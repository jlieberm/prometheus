{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1 id=\"tocheading\">Table of Contents</h1>\n<div id=\"toc\"></div>"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creating an ssh key\n\n\\#TODO"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creating new Instance\n\nTwo(+) possible ways\n\n1. **Recommended** Without using a volume (back-up will be done using snapshots):\n * Simply click on start a new instance on the [cern openstack web interface](https://openstack.cern.ch/dashboard/project/instances/)\n2. Using a volume (seems to be problematic to reactivate in case of issues --- I would have to study the subject deeper, if you have time to do so, maybe you can found out how to do using this way (please contact me if you do so :D ) ---, however it should allow you to recovery of [VM state on death of hypervisor](http://clouddocs.web.cern.ch/clouddocs/tutorial/boot_from_volume.html)):\n * Create a new volume from the wanted SLC system base. \n * On the volume tab, click on the volume and choose start a new instance.\n * Choose highest flavor available.\n\n\n## Very Important\n* Don't forget to add the ssh key-pair created in the last step to the instance in **both ways**, otherwise it won't be possible to log without entering password on this machine (it seems it is possible to change host key-pair information using [JSON](https://answers.launchpad.net/nova/+question/223104), but I haven't tried).\n\nWait until it's ready for log-in, and then continue installation."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Expanding VM disk size to flavour, or volume, size\n\nThe procedure I've followed was:"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo growpart /dev/vda 2\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```\nCHANGED: partition=2 start=821248 old: size=20150272 end=20971520 new: size=104035952,end=104857200\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Reboot instance** | **Reboot Instance** | **Reboot Instance** | **Reboot Instance** | **Reboot Instance** | **Reboot Instance** \n\nusing [cern openstack web interface](https://openstack.cern.ch/dashboard/project/instances/), then:"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo pvresize /dev/vda2\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "  ```\n  Physical volume \"/dev/vda2\" changed\n  1 physical volume(s) resized / 0 physical volume(s) not resized\n  ```"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh \nsudo lvextend -l +100%FREE /dev/mapper/VolGroup00-LogVol00\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "  ```\n  Size of logical volume VolGroup00/LogVol00 changed from 8.09 GiB (259 extents) to 48.09 GiB (1539 extents).\n  Logical volume LogVol00 successfully resized\n  ```"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo resize2fs /dev/mapper/VolGroup00-LogVol00\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```\nresize2fs 1.41.12 (17-May-2010)\nFilesystem at /dev/mapper/VolGroup00-LogVol00 is mounted on /; on-line resizing required\nold desc_blocks = 1, new_desc_blocks = 4\nPerforming an on-line resize of /dev/mapper/VolGroup00-LogVol00 to 12607488 (4k) blocks.\n```"
  },
  {
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "cell_type": "code",
   "source": "%%bash\ndf -H",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Filesystem            Size  Used Avail Use% Mounted on\n/dev/mapper/VolGroup00-LogVol00\n                       83G   34G   45G  43% /\ntmpfs                 4.2G     0  4.2G   0% /dev/shm\n/dev/vda1             398M  106M  272M  28% /boot\nAFS                   9.3G     0  9.3G   0% /afs\ncvmfs2                 25G   21G  3.9G  85% /cvmfs/atlas.cern.ch\n"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Installing LXPLUS like commands"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum groupinstall \"Development Tools\" -y\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```\nInstalled:\n  autoconf.noarch 0:2.63-5.1.el6      automake.noarch 0:1.11.1-4.el6     \n  bison.x86_64 0:2.4.1-5.el6          byacc.x86_64 0:1.9.20070509-7.el6       cscope.x86_64 0:15.6-6.el6      \n  ctags.x86_64 0:5.8-2.el6            diffstat.x86_64 0:1.51-2.el6       \n  doxygen.x86_64 1:1.6.1-6.el6 flex.x86_64 0:2.5.35-9.el6                     gcc.x86_64 0:4.4.7-16.el6       \n  gcc-c++.x86_64 0:4.4.7-16.el6       gcc-gfortran.x86_64 0:4.4.7-16.el6 \n  git.x86_64 0:1.7.1-3.el6_4.1        indent.x86_64 0:2.2.10-7.el6            intltool.noarch 0:0.41.0-1.1.el6\n  libtool.x86_64 0:2.2.6-15.5.el6     patchutils.x86_64 0:0.3.1-3.1.el6  \n  rcs.x86_64 0:5.7-37.el6             redhat-rpm-config.noarch 0:9.0.3-44.el6 rpm-build.x86_64 0:4.8.0-47.el6 \n  subversion.x86_64 0:1.6.11-15.el6_7 swig.x86_64 0:1.3.40-6.el6         \n  systemtap.x86_64 0:2.7-2.el6\n\nDependency Installed:\n  apr.x86_64 0:1.3.9-5.el6_2                 apr-util.x86_64 0:1.3.9-3.el6_0.1         \n  cloog-ppl.x86_64 0:0.15.7-1.2.el6          cpp.x86_64 0:4.4.7-16.el6                      \n  gdb.x86_64 0:7.2-83.el6                    gettext-devel.x86_64 0:0.17-18.el6        \n  gettext-libs.x86_64 0:0.17-18.el6          kernel-devel.x86_64 0:2.6.32-573.7.1.el6       \n  libart_lgpl.x86_64 0:2.3.20-5.1.el6        libgcj.x86_64 0:4.4.7-16.el6              \n  libgfortran.x86_64 0:4.4.7-16.el6          libstdc++-devel.x86_64 0:4.4.7-16.el6          \n  mpfr.x86_64 0:2.4.1-6.el6                  neon.x86_64 0:0.29.3-3.el6_4              \n  pakchois.x86_64 0:0.4-3.2.el6              perl-Error.noarch 1:0.17015-4.el6              \n  perl-Git.noarch 0:1.7.1-3.el6_4.1          ppl.x86_64 0:0.10.2-11.el6                \n  systemtap-client.x86_64 0:2.7-2.el6        systemtap-devel.x86_64 0:2.7-2.el6        \n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\n# Adding CERN users\n\nExecute following commands:"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum install -y cern-config-users\n# Add cern users:\n/usr/sbin/addusercern <account>\nsudo /usr/sbin/cern-config-users --setup-all\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adding CERN printers\n\nFirst, search the printer names by doing `/usr/sbin/lpadmincern --building XXXX --list `, and then add those you want with the command:\n"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\n/usr/sbin/lpadmincern printername --add\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Installing ATLAS CVMFS\n\nThis is needed to have access to most of the ATLAS software, as some Athena releases, RootCore, python versions used by ATLAS and so on...\nThe commands displayed are taken from [here](https://twiki.cern.ch/twiki/bin/view/AtlasComputing/Cvmfs21):\n"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\n# Suggestion: import the GPG key via HTTPS to ensure the integrity of the RPM file before installing\nsudo rpm --import https://cvmrepo.web.cern.ch/cvmrepo/yum/RPM-GPG-KEY-CernVM\n\n#for SL6 (SL5 users, please migrate to SL6):\nsudo rpm -Uvh http://cvmrepo.web.cern.ch/cvmrepo/yum/cvmfs/EL/6/`uname -i`/cvmfs-release-2-4.el6.noarch.rpm\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "``` \nRetrieving http://cvmrepo.web.cern.ch/cvmrepo/yum/cvmfs/EL/6/x86_64/cvmfs-release-2-4.el6.noarch.rpm\nPreparing...                ########################################### [100%]\n   1:cvmfs-release          ########################################### [100%]\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we install (for updating just change `yum install` to `yum update`) cvmfs:"
  },
  {
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "cell_type": "code",
   "source": "# for Tier3s and others:\nsudo yum install cvmfs cvmfs-config-default cvmfs-auto-setup -y",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then we head into configuration. Add the following file with (I've copied this file configuration from lxplus, which seems to work better then the configuration available on the link I've followed...):"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\ncat << EOF > default.local\nCVMFS_REPOSITORIES=atlas.cern.ch,atlas-condb.cern.ch,atlas-nightlies.cern.ch,sft.cern.ch\nCVMFS_QUOTA_LIMIT='23664'\nCVMFS_HTTP_PROXY='http://ca-proxy.cern.ch:3128;http://ca-proxy1.cern.ch:3128|http://ca-proxy2.cern.ch:3128|http://ca-proxy3.cern.ch:3128|http://ca-proxy4.cern.ch:3128|http://ca-proxy5.cern.ch:3128'\nCVMFS_CACHE_BASE='/var/lib/cvmfs'\nCVMFS_FORCE_SIGNING='yes'\nEOF\nsudo mkdir -p /etc/cvmfs/\nsudo mv default.local /etc/cvmfs\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Start services:"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo service autofs start\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```\nStarting automount: automount: program is already running.\n                                                           [  OK  ]\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Make sure to check each of the following commands outputs. I got some warnings on chksetup (which I ignored completely):\n\n```\nWarning: failed to access http://cernvmfs.gridpp.rl.ac.uk/cvmfs/atlas.cern.ch/.cvmfspublished through proxy DIRECT\nWarning: failed to use Geo-API with cernvmfs.gridpp.rl.ac.uk\nWarning: failed to use Geo-API with cvmfs.racf.bnl.gov\nWarning: failed to access http://cernvmfs.gridpp.rl.ac.uk/cvmfs/atlas-condb.cern.ch/.cvmfspublished through proxy DIRECT\nWarning: failed to use Geo-API with cernvmfs.gridpp.rl.ac.uk\nWarning: failed to use Geo-API with cvmfs.racf.bnl.gov\nWarning: failed to access http://cernvmfs.gridpp.rl.ac.uk/cvmfs/sft.cern.ch/.cvmfspublished through proxy DIRECT\nWarning: failed to use Geo-API with cernvmfs.gridpp.rl.ac.uk\nWarning: failed to use Geo-API with cvmfs.racf.bnl.gov\n```"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\n# Each of the following commands should have their outputs checked:\nsudo cvmfs_config chksetup # Printed some warnings for me, but seems to be ok.\nsudo cvmfs_config stat\nsudo cvmfs_config showconfig\nsudo cvmfs_config probe\n```\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, run the following command and check if no more ATLAS software is missing (this is done considering that the node would be a Tier3):"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\n/cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/utilities/installCheck.sh # Can be run without root permissions\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```\nyum install compat-db43.i686 compat-db43.x86_64 compat-expat1.i686 compat-expat1.x86_64 compat-libf2c-34.i686 compat-libf2c-34.x86_64 compat-libtermcap.i686 compat-libtermcap.x86_64 compat-openldap.x86_64 compat-readline5.i686 compat-readline5.x86_64 freetype-devel.i686 freetype-devel.x86_64 freetype.i686 glibc-devel.i686 glibc.i686 libaio.i686 libpng-devel.i686 libpng-devel.x86_64 libstdc++.i686 libuuid-devel.i686 libuuid-devel.x86_64 libXext-devel.i686 libXext-devel.x86_64 libXext.i686 libXft.i686 libxml2-devel.i686 libxml2-devel.x86_64 libxml2.i686 libXpm.i686 libXpm.x86_64 mesa-libGL-devel.i686 mesa-libGL-devel.x86_64 mesa-libGL.i686 mesa-libGLU-devel.i686 mesa-libGLU-devel.x86_64 mesa-libGLU.i686 ncurses-devel.i686 ncurses-devel.x86_64 openldap.i686 openssl098e.i686 openssl098e.x86_64 pam.i686 zlib-devel.i686 zlib-devel.x86_64 zlib.i686\n. Checking for missing yum groups ...\n. Checking that SELinuz is disabled ...\n.. SELinux is not disabled.\n..  You can disable it /etc/selinux/config and reboot\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "So, in this case:"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum install compat-db43.i686 compat-db43.x86_64 compat-expat1.i686 compat-expat1.x86_64 compat-libf2c-34.i686 compat-libf2c-34.x86_64 compat-libtermcap.i686 compat-libtermcap.x86_64 compat-openldap.x86_64 compat-readline5.i686 compat-readline5.x86_64 freetype-devel.i686 freetype-devel.x86_64 freetype.i686 glibc-devel.i686 glibc.i686 libaio.i686 libpng-devel.i686 libpng-devel.x86_64 libstdc++.i686 libuuid-devel.i686 libuuid-devel.x86_64 libXext-devel.i686 libXext-devel.x86_64 libXext.i686 libXft.i686 libxml2-devel.i686 libxml2-devel.x86_64 libxml2.i686 libXpm.i686 libXpm.x86_64 mesa-libGL-devel.i686 mesa-libGL-devel.x86_64 mesa-libGL.i686 mesa-libGLU-devel.i686 mesa-libGLU-devel.x86_64 mesa-libGLU.i686 ncurses-devel.i686 ncurses-devel.x86_64 openldap.i686 openssl098e.i686 openssl098e.x86_64 pam.i686 zlib-devel.i686 zlib-devel.x86_64 zlib.i686\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And also run `sudo vim /etc/selinux/config`, and edit it to be as follows:"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\n# This file controls the state of SELinux on the system.\n# SELINUX= can take one of these three values:\n#     enforcing - SELinux security policy is enforced.\n#     permissive - SELinux prints warnings instead of enforcing.\n#     disabled - No SELinux policy is loaded.\nSELINUX=disabled # Changed to disabled\n# SELINUXTYPE= can take one of these two values:\n#     targeted - Targeted processes are protected,\n#     mls - Multi Level Security protection.\nSELINUXTYPE=targeted\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Re-running the command after installing the other dependencies:"
  },
  {
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "cell_type": "code",
   "source": "%%bash\n/cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/utilities/installCheck.sh",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--------------------------------------------------------------------\nRedHat derived OS:\nScientific Linux CERN SLC release 6.7 (Carbon)\n--------------------------------------------------------------------\nChecking RedHat 6 derived OS ...\n. Checking for missing rpms ...\n. Checking for missing yum groups ...\n. Checking that SELinuz is disabled ...\nCompleted check.\n\n*******************************************************************************\nWhat to expect if there are no problems:\n  No missing rpms. (You can ignore strace64 if it shows up.)\n  SELinux disabling is only a recommendation if you have problems.\n*******************************************************************************\n\n"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Changing afs configuration\n\nYou might want to remove most of the afs default servers which are on the file `/usr/vice/etc/CellServDB.dist` and then reboot the machine. Using only /afs/cern.ch might be enought in most cases."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Installing VOMS (for Grid)\n\nWhat follows was taken from [here](https://wiki.egi.eu/wiki/EGI_IGTF_Release) (check using `yum` when installing  for the first time):"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nrpm -ivh http://linuxsoft.cern.ch/wlcg/sl6/x86_64/wlcg-voms-atlas-1.0.0-1.noarch.rpm\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Install voms command (the version may change as time passes, check it using `yum provides \"*/voms-proxy-init\"`):"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum install voms-clients-cpp -y\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We now install the grid host server references:"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo mkdir -p /etc/yum.repos.d; \nsudo wget http://repository.egi.eu/sw/production/cas/1/current/repo-files/EGI-trustanchors.repo -P /etc/yum.repos.d/\n```"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum install ca-policy-egi-core -y\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```\nInstalled:\n  ca-policy-egi-core.noarch 0:1.67-1                                                                                                                                              \n\nDependency Installed:\n  ca_AAACertificateServices.noarch 0:1.67-1               ca_AEGIS.noarch 0:1.67-1                                  ca_ANSPGrid.noarch 0:1.67-1                                  \n  ca_ASGCCA-2007.noarch 0:1.67-1                          ca_AddTrust-External-CA-Root.noarch 0:1.67-1              ca_ArmeSFo.noarch 0:1.67-1                                   \n  ca_AustrianGrid.noarch 0:1.67-1                         ca_BEGrid2008.noarch 0:1.67-1                             ca_BG-ACAD-CA.noarch 0:1.67-1                                \n  ca_BYGCA.noarch 0:1.67-1                                ca_BalticGrid.noarch 0:1.67-1                             ca_BrGrid.noarch 0:1.67-1                                    \n  ca_CALG.noarch 0:1.67-1                                 ca_CERN-GridCA.noarch 0:1.67-1                            ca_CERN-Root-2.noarch 0:1.67-1                               \n  ca_CESNET-CA-3.noarch 0:1.67-1                          ca_CESNET-CA-Root.noarch 0:1.67-1                         ca_CNIC.noarch 0:1.67-1                                      \n  ca_CNRS2.noarch 0:1.67-1                                ca_CNRS2-Grid-FR.noarch 0:1.67-1                          ca_CNRS2-Projets.noarch 0:1.67-1                             \n  ca_COMODO-RSA-CA.noarch 0:1.67-1                        ca_CyGrid.noarch 0:1.67-1                                 ca_DFN-GridGermany-Root.noarch 0:1.67-1                      \n  ca_DFN-SLCS.noarch 0:1.67-1                             ca_DZeScience.noarch 0:1.67-1                             ca_DigiCertAssuredIDRootCA-Root.noarch 0:1.67-1              \n  ca_DigiCertGridCA-1-Classic.noarch 0:1.67-1             ca_DigiCertGridCA-1G2-Classic.noarch 0:1.67-1             ca_DigiCertGridCA-1G2-Classic-2015.noarch 0:1.67-1           \n  ca_DigiCertGridRootCA-Root.noarch 0:1.67-1              ca_DigiCertGridTrustCA-Classic.noarch 0:1.67-1            ca_DigiCertGridTrustCAG2-Classic.noarch 0:1.67-1             \n  ca_EG-GRID.noarch 0:1.67-1                              ca_FNAL-SLCS.noarch 0:1.67-1                              ca_GermanGrid.noarch 0:1.67-1                                \n  ca_GridCanada.noarch 0:1.67-1                           ca_HKU.noarch 0:1.67-1                                    ca_HPCI.noarch 0:1.67-1                                      \n  ca_HellasGrid-CA-2006.noarch 0:1.67-1                   ca_HellasGrid-Root.noarch 0:1.67-1                        ca_IGCA.noarch 0:1.67-1                                      \n  ca_IHEP-2013.noarch 0:1.67-1                            ca_INFN-CA-2006.noarch 0:1.67-1                           ca_IRAN-GRID.noarch 0:1.67-1                                 \n  ca_InCommon-IGTF-Server-CA.noarch 0:1.67-1              ca_KEK.noarch 0:1.67-1                                    ca_KISTI-2007.noarch 0:1.67-1                                \n  ca_LACGridCA.noarch 0:1.67-1                            ca_LIPCA.noarch 0:1.67-1                                  ca_MARGI.noarch 0:1.67-1                                     \n  ca_MD-Grid.noarch 0:1.67-1                              ca_MREN-CA.noarch 0:1.67-1                                ca_MYIFAM.noarch 0:1.67-1                                    \n  ca_MaGrid.noarch 0:1.67-1                               ca_NCSA-slcs-2013.noarch 0:1.67-1                         ca_NCSA-tfca-2013.noarch 0:1.67-1                            \n  ca_NECTEC.noarch 0:1.67-1                               ca_NERSC-SLCS.noarch 0:1.67-1                             ca_NIIF-Root-CA-2.noarch 0:1.67-1                            \n  ca_NIKHEF.noarch 0:1.67-1                               ca_NorduGrid.noarch 0:1.67-1                              ca_PK-Grid-2007.noarch 0:1.67-1                              \n  ca_PSC-Myproxy-CA.noarch 0:1.67-1                       ca_PolishGrid.noarch 0:1.67-1                             ca_QuoVadis-Grid-ICA.noarch 0:1.67-1                         \n  ca_QuoVadis-Root-CA1.noarch 0:1.67-1                    ca_RDIG.noarch 0:1.67-1                                   ca_REUNA-ca.noarch 0:1.67-1                                  \n  ca_RomanianGRID.noarch 0:1.67-1                         ca_SDG.noarch 0:1.67-1                                    ca_SRCE.noarch 0:1.67-1                                      \n  ca_SiGNET-CA.noarch 0:1.67-1                            ca_SlovakGrid.noarch 0:1.67-1                             ca_TERENA-eScience-SSL-CA.noarch 0:1.67-1                    \n  ca_TERENA-eScience-SSL-CA-2.noarch 0:1.67-1             ca_TERENA-eScience-SSL-CA-3.noarch 0:1.67-1               ca_TERENAeSciencePersonalCA.noarch 0:1.67-1                  \n  ca_TERENAeSciencePersonalCA2.noarch 0:1.67-1            ca_TERENAeSciencePersonalCA3.noarch 0:1.67-1              ca_TRGrid.noarch 0:1.67-1                                    \n  ca_TSU-GE.noarch 0:1.67-1                               ca_UGRID.noarch 0:1.67-1                                  ca_UKeScienceCA-2A.noarch 0:1.67-1                           \n  ca_UKeScienceCA-2B.noarch 0:1.67-1                      ca_UKeScienceRoot-2007.noarch 0:1.67-1                    ca_UNAMgrid-ca.noarch 0:1.67-1                               \n  ca_UNLPGrid.noarch 0:1.67-1                             ca_UTN-USERFirst-Hardware.noarch 0:1.67-1                 ca_UTN-USERTrust-RSA-CA.noarch 0:1.67-1                      \n  ca_UTNAAAClient.noarch 0:1.67-1                         ca_UniandesCA.noarch 0:1.67-1                             ca_cilogon-silver.noarch 0:1.67-1                            \n  ca_pkIRISGrid.noarch 0:1.67-1                           ca_seegrid-ca-2013.noarch 0:1.67-1                       \n\nComplete!\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "***Also install java!*** This is needed by rucio/dq2:"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum install java-1.6.0-openjdk.x86_64 -y # It may be that rucio/dq2 needs other version in the future, so make sure to download the needed version \n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Installing development package (newer gcc, valgrind etc.)\n\nThis is quite important if you want to have one of the last versions of gcc and so on. The installation should be straight forward (as seen on [CERN reference](http://linux.web.cern.ch/linux/scientific6/docs/softwarecollections.shtml)):\n\n```zsh\nsudo yum install sl-release-scl -y\nyum install devassist09 devtoolset-3 git19 httpd24 mariadb55 mongodb24 \\\n               mysql55 nginx16 nodejs010 rh-passenger40 perl516 php54 php55 \\\n               postgresql92 python27 python33 rh-python34 rh-mariadb100 rh-mongodb26 \\\n               rh-mysql56 rh-nginx18 rh-perl520 rh-php56 rh-postgresql94 rh-varnish4 \\\n               ror40 rh-ror41 ruby193 ruby200 rh-ruby22 thermostat1 v8314 sclo-vagrant1\n```\n\nHowever, I had an error. To solve this I edited `/etc/yum.repos.d/slc6-scl.repo` and enabled the first repository (`[slc6-scl]`) by changing the enabled variable from 0 to 1.\n\nIf you don't have this file, you can download the sample from [here](http://linuxsoft.cern.ch/cern/scl/slc6-scl.repo), which is an obselete link installation [found here](http://linux.web.cern.ch/linux/scientific6/docs/softwarecollections-obsolete.shtml).\n\nTo use the developer kit do:\n\n```zsh\nscl enable devtoolset-3 zsh # or bash\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Some other very important packages"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Latex (TexLive 2015)\n\nThe version available on the SLC6 yum repositories is just a basic one. I wanted to have the full TexLive version, for doing so, these were the steps I've made (follow download and quickinstall instructions from [TexLive](https://www.tug.org/texlive/)):"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\nwget http://mirror.ctan.org/systems/texlive/tlnet/install-tl-unx.tar.gz\ntar xfvz install-tl-unx.tar.gz\nrm install-tl-unx.tar.gz\ncd install-tl-*\nsudo ./install-tl\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You will see the following screen:"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "```\nLoading http://ctan.math.utah.edu/ctan/tex-archive/systems/texlive/tlnet/tlpkg/texlive.tlpdb\nInstalling TeX Live 2015 from: http://ctan.math.utah.edu/ctan/tex-archive/systems/texlive/tlnet\nPlatform: x86_64-linux => 'GNU/Linux on x86_64'\nDistribution: net  (downloading)\nUsing URL: http://ctan.math.utah.edu/ctan/tex-archive/systems/texlive/tlnet\nDirectory for temporary files: /tmp\n\n======================> TeX Live installation procedure <=====================\n\n======>   Letters/digits in <angle brackets> indicate   <=======\n======>   menu items for commands or options            <=======\n\n Detected platform: GNU/Linux on x86_64\n\n <B> binary platforms: 1 out of 19\n\n <S> set installation scheme (scheme-full)\n\n <C> customizing installation collections\n     47 collections out of 48, disk space required: 4011 MB\n\n <D> directories:\n   TEXDIR (the main TeX directory):\n     /usr/local/texlive/2015\n   TEXMFLOCAL (directory for site-wide local files):\n     /usr/local/texlive/texmf-local\n   TEXMFSYSVAR (directory for variable and automatically generated data):\n     /usr/local/texlive/2015/texmf-var\n   TEXMFSYSCONFIG (directory for local config):\n     /usr/local/texlive/2015/texmf-config\n   TEXMFVAR (personal directory for variable and automatically generated data):\n     ~/.texlive2015/texmf-var\n   TEXMFCONFIG (personal directory for local config):\n     ~/.texlive2015/texmf-config\n   TEXMFHOME (directory for user-specific files):\n     ~/texmf   \n\n <O> options:  \n   [ ] use letter size instead of A4 by default\n   [X] allow execution of restricted list of programs via \\write18\n   [X] create all format files\n   [X] install macro/font doc tree\n   [X] install macro/font source tree\n   [ ] create symlinks to standard directories\n\n <V> set up for portable installation\n\nActions:\n <I> start installation to hard disk\n <H> help\n <Q> quit\n\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Insert I and wait the installation. If you want, you can specify a custom installation by changing the installation scheme (S). The default installation needs 4 GB space.\n\nNow we add the `TexLive` paths for all users:"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\ncat << EOF > TexLive_env.sh\nexport PATH=\"/usr/local/texlive/2015/bin/x86_64-linux:\\$PATH\"\nexport INFOPATH=\"/usr/local/texlive/2015/texmf-dist/doc/info:\\$INFOPATH\"\nexport MANPATH=\"/usr/local/texlive/2015/texmf-dist/doc/man:\\$MANPATH\"\nEOF\ntest \\! -d /etc/profile.d/ && sudo mkdir /etc/profile.d/\nsudo mv TexLive_env.sh /etc/profile.d/ # This will be sourced next time you log-in.\nsource /etc/profile.d/TexLive_env.sh\n```\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you want to test the installation, do:"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\nlatex small2e\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ATLAS, blas libraries\n\n```zsh\nsudo yum install -y atlas.x86_64 atlas-devel.x86_64 blas.x86_64 blas-devel.x86_64\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## X11 Access\n\nsudo yum install -y xorg-x11-xauth"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Armadillo\n\n```zsh\nsudo yum install -y armadillo\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## screen"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum install screen.x86_64 -y\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## pip install"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nwget https://bootstrap.pypa.io/get-pip.py\nsudo python get-pip.py\n# Update via: pip install -U pip\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## pyenv\n\nThis is needed to change the ipython installation accordenly to the environment you are using on RootCore or Athena.\nThe installation will be done for your cern account, and not for the node.\n\nWith it you can change python version and installation options. Thus, you can run python build with debug options and so on."
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\ngit clone https://github.com/yyuu/pyenv.git ~/.pyenv\nshell_config=\"$HOME/.bash_profile\" # If using zsh set it to $HOME/.zshenv\necho 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> $shell_config\necho 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> $shell_config\necho 'eval \"$(pyenv init -)\"' >> $shell_config\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**NOTE**: You may also want to not include it directly on bash_profile, but rather a file you could source later on. This is something you might consider, specially because RootCore won't set the python to the cvmfs version if it detects that you are using *pyenv*."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For being able to install and compile python on my afs account using the node configuration I had to also install the following packages:"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum install bzip2-libs.x86_64 readline-devel.x86_64 sqlite-devel.x86_64 openssl-devel.x86_64 -y\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Usage:**"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\n# Install python 2.7.4 for instance\npyenv install 2.7.4 \n# maybe you will want to install it with a shared library (I've set unicode to ucs4 b/c that's the version CERN uses):\nenv PYTHON_CONFIGURE_OPTS=\"--enable-shared --enable-unicode=ucs4\" pyenv install -v 2.7.4\n# Change the python to the locally installed 2.7.4 and also add the system python to path:\npyenv global 2.7.4 system\n# Now you can both use the python\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Btw: In order to install numpy and scipy, I had to use easy_install instead of pip:\n\n```zsh\neasy_install numpy\neasy_install pandas\npip install tornado\neasy_install bokeh\n```\n\nMaybe you will need to change every pip install by easy_install in order to use the right unicode..."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## IPython\n\n**Note**: ipython on current SLC6 version won't run the notebook because it seems not to be possible to install it on version 2.6."
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum install python-ipython-doc.noarch python-ipython-console.noarch -y\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### IPython Notebook and others:"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\npip install ipython[notebook] # or ipython\\[notebook\\] on zsh\npip install pyzmq\npip install jinja2\npip install tornado\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For forwarding the notebook so that it can be accessed outside, you will have to do as follows ([reference](http://www.hydro.washington.edu/~jhamman/hydro-logic/blog/2013/10/04/pybook-remote/)):"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "``` zsh\n# When inside CERN network\nssh -N -f -L localhost:<any_port_you_want_to_use>:localhost:<port_used_by_jupyter> <your_account>@<your_node>\n# When outside CERN network\nssh -f -L 8080:localhost:8080 <your_account>@lxplus.cern.ch ssh -f -L 8080:localhost:<port_used_by_jupyter> -N <your_account>@<your_node>\n```\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you need to end the port forwarding, find the process id by doing:"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\nps aux | grep ssh\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And then kill it using `kill <PID>`"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Jupyter\n\nSince you probably will get installed IPython 4.x (unless you use pip install for some wanted version), you will need to install jupyther as well. This is done following the documentation available [here](http://jupyter.readthedocs.org/en/latest/install.html#existing-python-new-jupyter).\n\nI've considered the case where we don't use anaconda:"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\npip install jupyter # I'm considering that you are installing using pyenv environment,\n                    # then run command with admin rights.\n# We also need to install yalm python support:\npip install pyyaml\n# Either:\npip install ipywidgets\npip install ipywidgets --upgrade\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extending Jupyter with plugins\n\nInstalling plugins will definetly improve the jupyther capabilities."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Several extensions in one pack\n\nFirst we will install the IPython-notebook-extensions using the github."
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\npip install psutil\ngit clone https://github.com/ipython-contrib/IPython-notebook-extensions\ncd IPython-notebook-extensions\npython setup.py install\ncd -\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then on your browser add after the port `/nbextensions` and turn on those you like."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####  Calico-spell\n\nInstead using aspell, jupyter indicates the use of calico aspell.\n\nOn notebook, open a code cell and run (this can be also run on terminal):"
  },
  {
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "cell_type": "code",
   "source": "!ipython install-nbextension --user https://bitbucket.org/ipre/calico/downloads/calico-spell-check-1.0.zip",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "downloading https://bitbucket.org/ipre/calico/downloads/calico-spell-check-1.0.zip to /tmp/tmpI4ePbv/calico-spell-check-1.0.zip\nextracting /tmp/tmpI4ePbv/calico-spell-check-1.0.zip to /afs/cern.ch/user/w/wsfreund/.local/share/jupyter/nbextensions\n"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then add another cell to load, in each notebook:"
  },
  {
   "metadata": {
    "collapsed": true,
    "trusted": true
   },
   "cell_type": "code",
   "source": "%%javascript\nrequire(['base/js/utils'],\nfunction(utils) {\n   utils.load_extensions('calico-spell-check');\n});",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If it is wanted to have it available on every jupyter notebook, modify `~/.jupyter_tuningtools/custom/custom.js` by adding:"
  },
  {
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "cell_type": "code",
   "source": "# %load ~/.jupyter_tuningtools/custom/custom.js\n# Add to the file:\nrequire(['base/js/utils'],\n        function(utils) {\n            utils.load_extensions('calico-spell-check');\n        });\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Aspell\n\nReferences [1](https://github.com/ipython-contrib/IPython-notebook-extensions/wiki/aspell), [2](http://calicoproject.org/ICalico#Installation_2). **NOTE**: Still working on this solution..."
  },
  {
   "metadata": {
    "collapsed": true,
    "run_control": {
     "marked": false
    }
   },
   "cell_type": "markdown",
   "source": "```zsh\n# Aspell plugin\nsudo yum install aspell aspell-devel.x86_64 -y\ngit clone https://github.com/WojciechMula/aspell-python.git\ncd aspell-python\npython setup.2.py build # or setup.3 for python 3\npython setup.2.py install \ncd -\nwget http://ftp.gnu.org/gnu/aspell/dict/en/aspell6-en-2015.04.24-0.tar.bz2\ntar xfvj aspell6-en-2015.04.24-0.tar.bz2\nrm aspell6-en-2015.04.24-0.tar.bz2\ncd aspell6-en-2015.04.24-0/\n./configure\nsudo make install\ncd -\naspell dump dicts \nnohup python ~/.local/share/jupyter/nbextensions/usability/aspell/ipy-aspell-server.py & # Start ipy aspell server\n# To change the language on aspell modify the line s = aspell.Speller('lang', 'en') content on ipy-aspell-server\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Table Of Contents\n\nWith the table of contents plugin available, add the following markdown text in the first cell of the notebook:"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```html\n<h1 id=\"tocheading\">Table of Contents</h1>\n<div id=\"toc\"></div>\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Use this other markdown cell to expand the table of contents information (adapted from [1](http://blog.nextgenetics.net/?e=102) and [2](https://github.com/kmahelona/ipython_notebook_goodies)). It is a good idea to have it as the last cell, since after you run it with shift-enter, it will get invisible, but you can click on it if you find the small area which it is occupying. This code is important to enable the TOC code above to get expanded."
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```html\n<script type=\"text/javascript\">\n    show=true;\n    function toggle(){\n        if (show){\n            $('div.input').hide();\n        }else{\n            $('div.input').show();\n        }\n        show = !show\n    }\n$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n</script>\n<a href=\"javascript:toggle()\" target=\"_self\"></a>\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Maybe you'll also need to download the TOC json files over as described here, but rather doing as follows:"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\ncurl -L https://rawgithub.com/minrk/ipython_extensions/master/nbextensions/toc.js > $JUPYTER_PATH/nbextensions/usability/toc2/toc.js\ncurl -L https://rawgithub.com/minrk/ipython_extensions/master/nbextensions/toc.css > $JUPYTER_PATH/nbextensions/usability/toc2/toc.css\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After you will have to do edit file `~/.jupyter/nbconfig/notebook.json` (if you don't have, you can create one by accessing the `/nbextensions` folder on the jupyter browser, or just create one with the following template):"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```json\n{\n  \"load_extensions\": {     \n    \"usability/toc2/toc\": true \n  }, \n}\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Gist upload button\n\nOne very useful thing is to have a buttom to upload the notebook to your gist with only one click. This can be done as follows:"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\nJUPYTER_PATH=$(python -c \"from jupyter_core.paths import jupyter_data_dir; print(jupyter_data_dir());\")\nmkdir -p $JUPYTER_PATH/nbextensions/usability/gist\ncurl -L https://rawgithub.com/minrk/ipython_extensions/master/nbextensions/gist.js > $JUPYTER_PATH/nbextensions/usability/gist/gist.js\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Activate the plugin by editing `~/.jupyter/nbconfig/notebook.json` and adding the following line to \"load_extensions\":"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```json\n\"usability/gist/gist\": true\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Then go to [github token generation](https://github.com/settings/tokens) and create one for you. I recommend that you add only gist permissions for this token.\n\nCopy the token generated and keep it somewhere so that you can copy and paste it everytime you want to upload the gist to github.\n\n**NOTE**: If you for some reason delete the gist file on github and cannot upload it anymore using the upload button, click on the menu edit button and choose `Edit Notebook Data`. Once there, just delete the gist file flag.\n\n**NOTE2**: When you rename one gist file, it will keep the old naming file on the gist. You can simply git clone your gist, remove the old files and commit, as:\n\n```zsh\ngit clone https://gist.github.com/1234567.git\ncd 1234567\nrm oldfile\ngit commit -a -m \"Removed old file\"\ngit push\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Exporting pdfs and others\n\nI had issues when trying to install pandoc which is needed to create pdfs due to conflict with SLC-EPEL and epel repository management.\n\nThe solution I found needs to temporarly overwrite CERN epel repository management to the latest management version so that we can retrieve pandoc rpms (which is 600 MB large and contains many libraries).\n\nTo avoid other conflicts later on, I moved the epel repository management files to inactive status. If you have to update pandoc or uninstall it, just remove the -inactive flags from the epel files."
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\npip install six # Needed to export pdfs and so on.\n## Installing pandoc\n# Here I do something which should be avoided, but I couldn't find another solution but to force \n# the temporary installation of the epel package management:\n# This is only needed if not using SLC6 CERN: sudo rpm -ivh --force http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm  \n# We then install the pandoc packages:\nsudo yum install pandoc ghc-pandoc ghc-pandoc-devel ghc-pandoc-types ghc-pandoc-types-devel -y\n# And disable the epel package management\n# Only if not using SLC6 CERN: sudo mv /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel.repo-inactive\n# Only if not using SLC6 CERN: sudo mv /etc/yum.repos.d/epel-testing.repo /etc/yum.repos.d/epel-testing.repo-inactive\n# Install python support to pandoc\npip install pandoc\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now you will be able to export HTML files, but for the pdf we will also need to install latex... this was [explained before here](#Latex-&#x28;TexLive-2015&#x29;). I had issues when trying to export, for better debugging your issues, you can use the following command line to check the errors:"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\nipython nbconvert --to pdf <NotebookSample.ipynb>\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I had then to install the following package:"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh \npip install requests\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I've also opened [an issue](https://github.com/jupyter/nbviewer/issues/513#issuecomment-146835643) on GitHub to try to solve it. First, I've updated jupyter nbconvert to be as the HEAD, for this, I've needed to execute the following commands:"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum install libcurl-devel -y\nexport PYCURL_SSL_LIBRARY=\"nss\"\neasy_install pycurl \n# Still waiting for updates:\npip install -e git+https://github.com/jupyter/nbconvert#egg=nbconvert\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Jupyter Drive\n\nThis doesn't work, I'll wait until documentation and community suport improves for IPython 4."
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\ngit clone git://github.com/jupyter/jupyter-drive.git\ncd jupyter-drive\npython setup.py build\npython setup.py install\n## On >=2.7\n#python -m jupyterdrive\n## Otherwise run like this\n#python -m jupyterdrive.__main__\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Dark code cells\n\n\\#TODO Follow installation from [here](https://www.pfenninger.org/posts/ipython-extension-to-toggle-dark-code-cells/)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## openstack\n\nThe openstack installation deserves a little bit more attention. During the tutorial writing time, the project which would make the openstack available on SLC6 removed the support for their binaries on Redhat 6, where the SLC6 is build upon (at least that's what I understood so far). So, it isn't possible to install using the epel and RDO project repositories.\n\nThe solution I found is available [here](https://clouddocs.web.cern.ch/clouddocs/clients/linux_client_installation.html).\n\nFor future reference, if the SLC version is upgraded, maybe the link you need to follow the instructions is available [here](http://clouddocs.web.cern.ch/clouddocs/advanced_topics/installing_your_own_openstack.html) (it doesn't work right now). "
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum update -y\nsudo rpm -ivh --nodeps http://cbs.centos.org/repos/cloud6-openstack-juno-candidate/x86_64/os/Packages/centos-release-openstack-juno-2.el6.noarch.rpm\nsudo yum install -y /usr/bin/{nova,glance,cinder,keystone,openstack}\n```\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Important** you will also need to install for having access to command `virt-sysprep` used for cloning snapshots:"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum install libguestfs-tools.x86_64 -y\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Enabling X11 forwarding\n\nTODO"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Some command you need is missing?\n\nIf a command is missing, it can be found on yum by doing (if not, [duckduckgo](https://duckduckgo.com/) or [google](https://google.com) it):"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nsudo yum provides \"*/command\"\n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cloning the VM and saving snapshots for future node recovery\n\nIt's important to keep your VM configuration saved by doing snapshots from time to time. This is explained [here](http://clouddocs.web.cern.ch/clouddocs/using_openstack/backups.html), in this topic we will walk through cloning our just created VM to another node as it is possible to have two large nodes for the current CERN quota.\n\nIn order to create a snapshot, you can do it via website [here](https://openstack.cern.ch/dashboard/project/instances/). Latter we also explain how to do so via command line.\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configure your openstack\n\nFirst, go to the [cloud infrastructure site on tab access and security](https://openstack.cern.ch/dashboard/project/access_and_security/), click on download open stack rc file. Send it to your cern afs account and source it every time you want to use openstack or nova. \n\n## Create and start a snapshot"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "```zsh\nopenstack server image create --name <snapshotname> --wait <nodename> # Create a snapshot via command line\nopenstack image show <snpashotname> # Show snapshot information\n# openstack server rebuild --image <snapshotname> <nodename> ## Re-roll node to a previous snapshot if needed\nopenstack image save --file <snapshot_localfile_path>.qcow2 <snapshotname> # Copy snapshot to local host\n# For this command make sure you have followed the important note on openstack installation!\nvirt-sysprep -a <snapshot_localfile_path>.qcow2 # Clear node information for making possible to create another node from this image. \nopenstack image create --file <snapshot_localfile> --property os=LINUX --disk-format=qcow2 --container-format=bare <clean_image_name>\n# Upload to glance the cleaned snapshot\n# Now, create the new host:\nopenstack server create --key-name <your_key_name> --flavor m1.large --image <clean_image_name> <clone_nodename>\n```\n\nAfter creating the new machine node, it is still needed to correct the Kerberos `keytab` file. You can do this by doing as root:\n\n```zsh\nmv krb5.keytab krb5.keytab-bkg\ncern-get-keytab\n```\n\nYou may also need to update time on the snapshotted node:\n\n\n```zsh\nservice ntpd stop\nntpdate lxplus.cern.ch\nservice ntpd start\n```\n\n\nYou might need to update the keytab from the host:\n\n```\ncern-get-keytab --hostname <node_name>\n# Use `cern-config-keytab -v -f` to fix the configuration pointing to the correct host\n\n```\n\nand check on another host (lxplus):\n\n```\nkinit -R; kvno host/<node_ip>@CERN.CH\n```\n\n*Finally, it is also needed to change the kerberos autority from the host (I found help [here](https://twiki.cern.ch/twiki/bin/view/LinuxSupport/SSHatCERNFAQ#Kerberos_authentication_not_work), [here](https://twiki.cern.ch/twiki/bin/view/LinuxSupport/SSHatCERNFAQ#Kerberos_authentication_not_work), [here](http://clouddocs.web.cern.ch/clouddocs/using_openstack/backups.html), and contacted their support which be done via helpdesk). In order to do this, first we need to correct CERN information of the node in the LanDB (you can check the information from the node in the LanDB by accessing https://network.cern.ch/sc/fcgi/sc.fcgi?Action=SearchForDisplay&DeviceName=___node_name___):* **This step can be ignored as it was updated in the documentation above, however it might be useful reference if you forget to use the -os during the image creation**\n\n```\nopenstack server set --property landb-os=\"LINUX\" <node_name>\nklist -kt\n```\n\nWait 1 day (it will take some hours, but quite a few) and then do cern-get-keytab as stated above.\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Issues on the node\n\nHope you can find some helpful information below, where I catalog some issues that I have faced.\n\n\n## Out of Space related issues\n\nThese errors may happen when the node get out of space.\n\n### Empty afs folders which shouldn't be empty\n\nDo:\n\n```\nfs setca 1\nfs setca 0\n```\n\nThis will reset your afs cache (taken from [here](https://lists.openafs.org/pipermail/openafs-info/2004-November/015351.html)).\n\n### Connection timeout to specified afs folders\n\nYou can flush a volume or a mount space by doing:\n\n```\nfs flushmount /afs/cern.ch/work\nfs flushvolume /afs/cern.ch/work\n```\n\nTaken from [here](https://lists.openafs.org/pipermail/openafs-info/2012-August/038457.html)\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Accessing host as root\n\nInstead of logging with your user, if you are the owner of the ssh key-pair, you can then just change the ssh tunnel user to root to log into the root account. For instance, you could have the following tunnel aliases:"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "```zsh\nalias prefered='ssh -A -t -l <your_account> lxplus.cern.ch ssh -A -t -l <your_account> <your_host_name>'\nalias preferedroot='ssh -A -t -l <your_account> lxplus.cern.ch ssh -A -t -l root <your_host_name>'     \n```"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optional (and recommended) packages\n\n## Vim 7.4\n\nTo install recent VIM version do:\n\n`sudo yum install vim-enhanced.x86_64`\n\nHowever, if you need `lua` and `X11` access on VIM, you will have to download an install from source:\n\nInstall lua development:\n\n```zsh\nyum -y install lua-devel\n```\n\nInstall lua JIT:\n\n```zsh\ngit clone http://luajit.org/git/luajit-2.0.git\ncd luajit-2.0\nmake \nmake install\n```\n\nFor X11, you'll need to install the development package to have access to header files:\n\n```zsh\nyum groupinstall \"X Window System\"\nyum groupinstall \"CERN Addons X11\"\nyum install /usr/include/X11/Intrinsic.h\n```\n\nAnd the last dependence, if you need ruby, install it:\n\n```zsh\nyum install ruby ruby-devel\n```\n\nAt last but not least, install vim (you'll have to use a valid python2.7 path):\n\n```zsh\ngit clone https://github.com/vim/vim.git\ncd vim\n./configure --with-features=huge  \\\n            --enable-multibyte \\\n            --enable-rubyinterp \\\n            --enable-pythoninterp \\\n            --with-python-config-dir=/afs/cern.ch/user/w/wsfreund/.pyenv/versions/2.7.4/lib/python2.7/config \\\n            --enable-luainterp \\\n            --with-x --enable-cscope --prefix=/usr --with-luajit\nmake VIMRUNTIMEDIR=/usr/share/vim/vim74        \nsudo make install\n```\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## htop\n\n`sudo yum install htop.x86_64`"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## evince\n\nUsed for viewing pdfs.\n\n`sudo yum install evince`"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Unsolved issues\n\n## SSL handshake issues\n\nIt seems that I'm having issues with the nss SSL library. I'll have to check how to fix this, as it is stopping me from using curl and other things dependent on SSL, such as pbook."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Managing information\n\nHere, I try to catalog what commands are usuful for retrieving and changing information on the images and nodes.\n\nFirst, you can use glance to check the images information:\n"
  },
  {
   "metadata": {
    "collapsed": false,
    "trusted": true
   },
   "cell_type": "code",
   "source": "%%bash\nglance --help",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "usage: glance [--version] [-d] [-v] [--get-schema] [--timeout TIMEOUT] [--no-ssl-compression] [-f] [--os-image-url OS_IMAGE_URL] [--os-image-api-version OS_IMAGE_API_VERSION] [-k] [--os-cert OS_CERT]\n              [--cert-file OS_CERT] [--os-key OS_KEY] [--key-file OS_KEY] [--os-cacert <ca-certificate-file>] [--ca-file OS_CACERT] [--os-username OS_USERNAME] [--os-user-id OS_USER_ID]\n              [--os-user-domain-id OS_USER_DOMAIN_ID] [--os-user-domain-name OS_USER_DOMAIN_NAME] [--os-project-id OS_PROJECT_ID] [--os-project-name OS_PROJECT_NAME]\n              [--os-project-domain-id OS_PROJECT_DOMAIN_ID] [--os-project-domain-name OS_PROJECT_DOMAIN_NAME] [--os-password OS_PASSWORD] [--os-tenant-id OS_TENANT_ID] [--os-tenant-name OS_TENANT_NAME]\n              [--os-auth-url OS_AUTH_URL] [--os-region-name OS_REGION_NAME] [--os-auth-token OS_AUTH_TOKEN] [--os-service-type OS_SERVICE_TYPE] [--os-endpoint-type OS_ENDPOINT_TYPE]\n              <subcommand> ...\n\nCommand-line interface to the OpenStack Images API.\n\nPositional arguments:\n  <subcommand>\n    image-create        Create a new image.\n    image-delete        Delete specified image(s).\n    image-download      Download a specific image.\n    image-list          List images you can access.\n    image-show          Describe a specific image.\n    image-update        Update a specific image.\n    member-create       Share a specific image with a tenant.\n    member-delete       Remove a shared image from a tenant.\n    member-list         Describe sharing permissions by image or tenant.\n    bash-completion     Prints all of the commands and options to stdout so that the\n    help                Display help about this program or one of its subcommands.\n\nOptional arguments:\n  --version             show program's version number and exit\n  -d, --debug           Defaults to env[GLANCECLIENT_DEBUG].\n  -v, --verbose         Print more verbose output\n  --get-schema          Ignores cached copy and forces retrieval of schema that generates portions of the help text. Ignored with API version 1.\n  --timeout TIMEOUT     Number of seconds to wait for a response\n  --no-ssl-compression  Disable SSL compression when using https.\n  -f, --force           Prevent select actions from requesting user confirmation.\n  --os-image-url OS_IMAGE_URL\n                        Defaults to env[OS_IMAGE_URL]. If the provided image url contains a a version number and `--os-image-api-version` is omitted the version of the URL will be picked as the image\n                        api version to use.\n  --os-image-api-version OS_IMAGE_API_VERSION\n                        Defaults to env[OS_IMAGE_API_VERSION] or 1.\n  -k, --insecure        Explicitly allow glanceclient to perform \"insecure SSL\" (https) requests. The server's certificate will not be verified against any certificate authorities. This option should be\n                        used with caution.\n  --os-cert OS_CERT     Path of certificate file to use in SSL connection. This file can optionally be prepended with the private key.\n  --cert-file OS_CERT   DEPRECATED! Use --os-cert.\n  --os-key OS_KEY       Path of client key to use in SSL connection. This option is not necessary if your key is prepended to your cert file.\n  --key-file OS_KEY     DEPRECATED! Use --os-key.\n  --os-cacert <ca-certificate-file>\n                        Path of CA TLS certificate(s) used to verify the remote server's certificate. Without this option glance looks for the default system CA certificates.\n  --ca-file OS_CACERT   DEPRECATED! Use --os-cacert.\n  --os-username OS_USERNAME\n                        Defaults to env[OS_USERNAME].\n  --os-user-id OS_USER_ID\n                        Defaults to env[OS_USER_ID].\n  --os-user-domain-id OS_USER_DOMAIN_ID\n                        Defaults to env[OS_USER_DOMAIN_ID].\n  --os-user-domain-name OS_USER_DOMAIN_NAME\n                        Defaults to env[OS_USER_DOMAIN_NAME].\n  --os-project-id OS_PROJECT_ID\n                        Another way to specify tenant ID. This option is mutually exclusive with --os-tenant-id. Defaults to env[OS_PROJECT_ID].\n  --os-project-name OS_PROJECT_NAME\n                        Another way to specify tenant name. This option is mutually exclusive with --os-tenant-name. Defaults to env[OS_PROJECT_NAME].\n  --os-project-domain-id OS_PROJECT_DOMAIN_ID\n                        Defaults to env[OS_PROJECT_DOMAIN_ID].\n  --os-project-domain-name OS_PROJECT_DOMAIN_NAME\n                        Defaults to env[OS_PROJECT_DOMAIN_NAME].\n  --os-password OS_PASSWORD\n                        Defaults to env[OS_PASSWORD].\n  --os-tenant-id OS_TENANT_ID\n                        Defaults to env[OS_TENANT_ID].\n  --os-tenant-name OS_TENANT_NAME\n                        Defaults to env[OS_TENANT_NAME].\n  --os-auth-url OS_AUTH_URL\n                        Defaults to env[OS_AUTH_URL].\n  --os-region-name OS_REGION_NAME\n                        Defaults to env[OS_REGION_NAME].\n  --os-auth-token OS_AUTH_TOKEN\n                        Defaults to env[OS_AUTH_TOKEN].\n  --os-service-type OS_SERVICE_TYPE\n                        Defaults to env[OS_SERVICE_TYPE].\n  --os-endpoint-type OS_ENDPOINT_TYPE\n                        Defaults to env[OS_ENDPOINT_TYPE].\n\nSee \"glance help COMMAND\" for help on a specific command.\n"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adding ROOT keys\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Configure ROOT ssh keys by adding them to the file `/root/.ssh/authorized_keys`.\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<script type=\"text/javascript\">\n    show=true;\n    function toggle(){\n        if (show){\n            $('div.input').hide();\n        }else{\n            $('div.input').show();\n        }\n        show = !show\n    }\n$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')\n</script>\n<a href=\"javascript:toggle()\" target=\"_self\"></a>"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python2",
   "display_name": "Python 2",
   "language": "python"
  },
  "latex_envs": {
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "cite_by": "apalike",
   "bibliofile": "biblio.bib",
   "eqNumInitial": 0
  },
  "language_info": {
   "mimetype": "text/x-python",
   "nbconvert_exporter": "python",
   "name": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "version": 2,
    "name": "ipython"
   }
  },
  "toc": {
   "toc_section_display": "none",
   "toc_threshold": 4,
   "toc_window_display": false,
   "toc_number_sections": true,
   "toc_cell": true
  },
  "gist_id": "7e57bde9e08a9f7c4c46",
  "hide_input": false
 },
 "nbformat": 4,
 "nbformat_minor": 0
}